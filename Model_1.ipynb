{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.runn import *\n",
    "import zsyGame as zsy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import random_mini_batches, predict\n",
    "import tf_utils as tu\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import utils.data as data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_A, X_B, Y_A, Y_B = data.dataFileToLabeledData_1(r'data\\Model_1\\T100k_QvQ.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_Train = np.concatenate([X_A, X_B[:,:int(X_A.shape[1]*.96)]], axis = 1)\n",
    "X_Dev = X_B[:,int(X_A.shape[1]*.96):]\n",
    "\n",
    "Y_Train = data.convertY(np.concatenate([Y_A, Y_B[:,:int(X_A.shape[1]*.96)]], axis=1), 0.9)\n",
    "Y_Dev = Y_B[:,int(X_A.shape[1]*.96):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9844)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  0.,   1.,   2., ...,  11.,  12.,  13.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original Y is Y[0] = 1 if win, -1 if lose\n",
    "# Y[1] is how many steps away from the end of the game\n",
    "def convertY(Y, discount):\n",
    "    return (Y[0]*discount**Y[1]).reshape(1,-1)\n",
    "\n",
    "def convertYToLogistic(Y, discount):\n",
    "    return (convertY(Y, discount) + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def initialize_parameters(n_x, n_1, n_2, n_3=1):\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [n_1, n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [n_1,1], initializer = tf.zeros_initializer)\n",
    "    W2 = tf.get_variable(\"W2\", [n_2, n_1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [n_2,1], initializer = tf.zeros_initializer)\n",
    "    W3 = tf.get_variable(\"W3\", [n_3, n_2], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [n_3,1], initializer = tf.zeros_initializer)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters, keep_prob):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X),b1)                                       # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.dropout(tf.nn.relu(Z1), keep_prob)                                             # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1),b2)                                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.dropout(tf.nn.relu(Z2), keep_prob)                                               # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2),b3)                                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    predictions = tf.transpose(tf.sigmoid(Z3))\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.losses.log_loss(labels, predictions)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, keep_prob, n_1, n_2, n_3=1, learning_rate = 0.001,\n",
    "          num_epochs = 1500, minibatch_size = 1024, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    dev_costs = []\n",
    "    print(\"nx:%d ny:%d, m:%d\"%(n_x, n_y, m))\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters(n_x, n_1, n_2, n_3)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters, keep_prob)\n",
    "    Z3_ = forward_propagation(X, parameters, 1.0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    cost_ = compute_cost(Z3_, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            if(epoch==0):\n",
    "                tic0 = time.time()\n",
    "            if(epoch==10):\n",
    "                tic10 = time.time()\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            if(epoch==0):\n",
    "                print(\"num minibatches:%d\"%(num_minibatches))\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            tic = time.time()\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y:minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            toc = time.time()\n",
    "            if epoch == 0:\n",
    "                print (\"\\tEpoch time:%d seconds\"%(toc-tic))\n",
    "            if epoch == 10:\n",
    "                print (\"\\tAve epoch time: %f\"%((tic10-tic0)/10))\n",
    "                print (\"\\t100 epochs will take %s\"%(timedelta(seconds=10*(tic10-tic0))))\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and (epoch % 5 == 0 or epoch < 10):\n",
    "                dev_cost = sess.run(cost_, feed_dict={X: X_test, Y:Y_test})\n",
    "            if print_cost == True and (epoch % 10 == 0 or epoch < 10):\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                print (\"\\tDev error (no dropout): %f\"%(dev_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                dev_costs.append(dev_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        xrange = 5*np.arange(num_epochs/5)\n",
    "        plt.plot(xrange, np.squeeze(costs), xrange, np.squeeze(dev_costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        train_cost = sess.run(cost_, feed_dict={X: X_train, Y:Y_train})\n",
    "        dev_cost = sess.run(cost_, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "        print (\"Train cost (No dropout):\", train_cost)\n",
    "        print (\"Test cost (No dropout):\", dev_cost)\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCosts(X, Y, parameters):\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    x = tf.placeholder(\"float\", [300, None])\n",
    "    Z3 = tu.forward_propagation_for_predict(x, params)\n",
    "    A3 = tf.transpose(tf.sigmoid(Z3))\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.losses.log_loss(labels, A3)\n",
    "    sess = tf.Session()\n",
    "    cost = sess.run(cost, feed_dict = {x: X})  \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx:300 ny:1, m:2759501\n",
      "num minibatches:2694\n",
      "\tEpoch time:85 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2, 9844) for Tensor 'Placeholder_1:0', which has shape '(1, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2541d74d3679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_Dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-828e1e0430bc>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, keep_prob, n_1, n_2, n_3, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Print the cost every epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[0mdev_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Cost after epoch %i: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda2\\envs\\cs131\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda2\\envs\\cs131\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1105\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (2, 9844) for Tensor 'Placeholder_1:0', which has shape '(1, ?)'"
     ]
    }
   ],
   "source": [
    "parameters_2 = model(X_Train, Y_Train, X_Dev, Y_Dev, 0.5, 200, 40, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e281e041e3f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomputeCosts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "computeCosts(X_Train, Y_Train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'W1/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'W1' type=VariableV2>,\n",
       " <tf.Operation 'W1/Assign' type=Assign>,\n",
       " <tf.Operation 'W1/read' type=Identity>,\n",
       " <tf.Operation 'b1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b1' type=VariableV2>,\n",
       " <tf.Operation 'b1/Assign' type=Assign>,\n",
       " <tf.Operation 'b1/read' type=Identity>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'W2/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'W2' type=VariableV2>,\n",
       " <tf.Operation 'W2/Assign' type=Assign>,\n",
       " <tf.Operation 'W2/read' type=Identity>,\n",
       " <tf.Operation 'b2/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b2' type=VariableV2>,\n",
       " <tf.Operation 'b2/Assign' type=Assign>,\n",
       " <tf.Operation 'b2/read' type=Identity>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'W3/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'W3' type=VariableV2>,\n",
       " <tf.Operation 'W3/Assign' type=Assign>,\n",
       " <tf.Operation 'W3/read' type=Identity>,\n",
       " <tf.Operation 'b3/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b3' type=VariableV2>,\n",
       " <tf.Operation 'b3/Assign' type=Assign>,\n",
       " <tf.Operation 'b3/read' type=Identity>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'Add' type=Add>,\n",
       " <tf.Operation 'Relu' type=Relu>,\n",
       " <tf.Operation 'dropout/keep_prob' type=Const>,\n",
       " <tf.Operation 'dropout/Shape' type=Shape>,\n",
       " <tf.Operation 'dropout/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'dropout/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'dropout/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'dropout/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'dropout/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'dropout/random_uniform' type=Add>,\n",
       " <tf.Operation 'dropout/add' type=Add>,\n",
       " <tf.Operation 'dropout/Floor' type=Floor>,\n",
       " <tf.Operation 'dropout/div' type=RealDiv>,\n",
       " <tf.Operation 'dropout/mul' type=Mul>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'Add_1' type=Add>,\n",
       " <tf.Operation 'Relu_1' type=Relu>,\n",
       " <tf.Operation 'dropout_1/keep_prob' type=Const>,\n",
       " <tf.Operation 'dropout_1/Shape' type=Shape>,\n",
       " <tf.Operation 'dropout_1/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'dropout_1/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'dropout_1/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'dropout_1/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'dropout_1/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'dropout_1/random_uniform' type=Add>,\n",
       " <tf.Operation 'dropout_1/add' type=Add>,\n",
       " <tf.Operation 'dropout_1/Floor' type=Floor>,\n",
       " <tf.Operation 'dropout_1/div' type=RealDiv>,\n",
       " <tf.Operation 'dropout_1/mul' type=Mul>,\n",
       " <tf.Operation 'MatMul_2' type=MatMul>,\n",
       " <tf.Operation 'Add_2' type=Add>,\n",
       " <tf.Operation 'MatMul_3' type=MatMul>,\n",
       " <tf.Operation 'Add_3' type=Add>,\n",
       " <tf.Operation 'Relu_2' type=Relu>,\n",
       " <tf.Operation 'dropout_2/keep_prob' type=Const>,\n",
       " <tf.Operation 'MatMul_4' type=MatMul>,\n",
       " <tf.Operation 'Add_4' type=Add>,\n",
       " <tf.Operation 'Relu_3' type=Relu>,\n",
       " <tf.Operation 'dropout_3/keep_prob' type=Const>,\n",
       " <tf.Operation 'MatMul_5' type=MatMul>,\n",
       " <tf.Operation 'Add_5' type=Add>,\n",
       " <tf.Operation 'Sigmoid' type=Sigmoid>,\n",
       " <tf.Operation 'transpose/Rank' type=Rank>,\n",
       " <tf.Operation 'transpose/sub/y' type=Const>,\n",
       " <tf.Operation 'transpose/sub' type=Sub>,\n",
       " <tf.Operation 'transpose/Range/start' type=Const>,\n",
       " <tf.Operation 'transpose/Range/delta' type=Const>,\n",
       " <tf.Operation 'transpose/Range' type=Range>,\n",
       " <tf.Operation 'transpose/sub_1' type=Sub>,\n",
       " <tf.Operation 'transpose' type=Transpose>,\n",
       " <tf.Operation 'transpose_1/Rank' type=Rank>,\n",
       " <tf.Operation 'transpose_1/sub/y' type=Const>,\n",
       " <tf.Operation 'transpose_1/sub' type=Sub>,\n",
       " <tf.Operation 'transpose_1/Range/start' type=Const>,\n",
       " <tf.Operation 'transpose_1/Range/delta' type=Const>,\n",
       " <tf.Operation 'transpose_1/Range' type=Range>,\n",
       " <tf.Operation 'transpose_1/sub_1' type=Sub>,\n",
       " <tf.Operation 'transpose_1' type=Transpose>,\n",
       " <tf.Operation 'log_loss/add/y' type=Const>,\n",
       " <tf.Operation 'log_loss/add' type=Add>,\n",
       " <tf.Operation 'log_loss/Log' type=Log>,\n",
       " <tf.Operation 'log_loss/Mul' type=Mul>,\n",
       " <tf.Operation 'log_loss/Neg' type=Neg>,\n",
       " <tf.Operation 'log_loss/sub/x' type=Const>,\n",
       " <tf.Operation 'log_loss/sub' type=Sub>,\n",
       " <tf.Operation 'log_loss/sub_1/x' type=Const>,\n",
       " <tf.Operation 'log_loss/sub_1' type=Sub>,\n",
       " <tf.Operation 'log_loss/add_1/y' type=Const>,\n",
       " <tf.Operation 'log_loss/add_1' type=Add>,\n",
       " <tf.Operation 'log_loss/Log_1' type=Log>,\n",
       " <tf.Operation 'log_loss/Mul_1' type=Mul>,\n",
       " <tf.Operation 'log_loss/sub_2' type=Sub>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/weights' type=Const>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/weights/shape' type=Const>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/weights/rank' type=Const>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/values/shape' type=Shape>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/values/rank' type=Const>,\n",
       " <tf.Operation 'log_loss/assert_broadcastable/static_scalar_check_success' type=NoOp>,\n",
       " <tf.Operation 'log_loss/ToFloat_3/x' type=Const>,\n",
       " <tf.Operation 'log_loss/Mul_2' type=Mul>,\n",
       " <tf.Operation 'log_loss/Const' type=Const>,\n",
       " <tf.Operation 'log_loss/Sum' type=Sum>,\n",
       " <tf.Operation 'log_loss/num_present/Equal/y' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/Equal' type=Equal>,\n",
       " <tf.Operation 'log_loss/num_present/zeros_like' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/ones_like/Shape' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss/num_present/Select' type=Select>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/assert_broadcastable/values/shape' type=Shape>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/assert_broadcastable/values/rank' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success' type=NoOp>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/ones_like/Shape' type=Shape>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss/num_present/broadcast_weights' type=Mul>,\n",
       " <tf.Operation 'log_loss/num_present/Const' type=Const>,\n",
       " <tf.Operation 'log_loss/num_present' type=Sum>,\n",
       " <tf.Operation 'log_loss/Const_1' type=Const>,\n",
       " <tf.Operation 'log_loss/Sum_1' type=Sum>,\n",
       " <tf.Operation 'log_loss/Greater/y' type=Const>,\n",
       " <tf.Operation 'log_loss/Greater' type=Greater>,\n",
       " <tf.Operation 'log_loss/Equal/y' type=Const>,\n",
       " <tf.Operation 'log_loss/Equal' type=Equal>,\n",
       " <tf.Operation 'log_loss/ones_like/Shape' type=Const>,\n",
       " <tf.Operation 'log_loss/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss/Select' type=Select>,\n",
       " <tf.Operation 'log_loss/div' type=RealDiv>,\n",
       " <tf.Operation 'log_loss/zeros_like' type=Const>,\n",
       " <tf.Operation 'log_loss/value' type=Select>,\n",
       " <tf.Operation 'Sigmoid_1' type=Sigmoid>,\n",
       " <tf.Operation 'transpose_2/Rank' type=Rank>,\n",
       " <tf.Operation 'transpose_2/sub/y' type=Const>,\n",
       " <tf.Operation 'transpose_2/sub' type=Sub>,\n",
       " <tf.Operation 'transpose_2/Range/start' type=Const>,\n",
       " <tf.Operation 'transpose_2/Range/delta' type=Const>,\n",
       " <tf.Operation 'transpose_2/Range' type=Range>,\n",
       " <tf.Operation 'transpose_2/sub_1' type=Sub>,\n",
       " <tf.Operation 'transpose_2' type=Transpose>,\n",
       " <tf.Operation 'transpose_3/Rank' type=Rank>,\n",
       " <tf.Operation 'transpose_3/sub/y' type=Const>,\n",
       " <tf.Operation 'transpose_3/sub' type=Sub>,\n",
       " <tf.Operation 'transpose_3/Range/start' type=Const>,\n",
       " <tf.Operation 'transpose_3/Range/delta' type=Const>,\n",
       " <tf.Operation 'transpose_3/Range' type=Range>,\n",
       " <tf.Operation 'transpose_3/sub_1' type=Sub>,\n",
       " <tf.Operation 'transpose_3' type=Transpose>,\n",
       " <tf.Operation 'log_loss_1/add/y' type=Const>,\n",
       " <tf.Operation 'log_loss_1/add' type=Add>,\n",
       " <tf.Operation 'log_loss_1/Log' type=Log>,\n",
       " <tf.Operation 'log_loss_1/Mul' type=Mul>,\n",
       " <tf.Operation 'log_loss_1/Neg' type=Neg>,\n",
       " <tf.Operation 'log_loss_1/sub/x' type=Const>,\n",
       " <tf.Operation 'log_loss_1/sub' type=Sub>,\n",
       " <tf.Operation 'log_loss_1/sub_1/x' type=Const>,\n",
       " <tf.Operation 'log_loss_1/sub_1' type=Sub>,\n",
       " <tf.Operation 'log_loss_1/add_1/y' type=Const>,\n",
       " <tf.Operation 'log_loss_1/add_1' type=Add>,\n",
       " <tf.Operation 'log_loss_1/Log_1' type=Log>,\n",
       " <tf.Operation 'log_loss_1/Mul_1' type=Mul>,\n",
       " <tf.Operation 'log_loss_1/sub_2' type=Sub>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/weights' type=Const>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/weights/shape' type=Const>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/weights/rank' type=Const>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/values/shape' type=Shape>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/values/rank' type=Const>,\n",
       " <tf.Operation 'log_loss_1/assert_broadcastable/static_scalar_check_success' type=NoOp>,\n",
       " <tf.Operation 'log_loss_1/ToFloat_3/x' type=Const>,\n",
       " <tf.Operation 'log_loss_1/Mul_2' type=Mul>,\n",
       " <tf.Operation 'log_loss_1/Const' type=Const>,\n",
       " <tf.Operation 'log_loss_1/Sum' type=Sum>,\n",
       " <tf.Operation 'log_loss_1/num_present/Equal/y' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/Equal' type=Equal>,\n",
       " <tf.Operation 'log_loss_1/num_present/zeros_like' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/ones_like/Shape' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss_1/num_present/Select' type=Select>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/assert_broadcastable/weights/shape' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/assert_broadcastable/weights/rank' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/assert_broadcastable/values/shape' type=Shape>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/assert_broadcastable/values/rank' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success' type=NoOp>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/ones_like/Shape' type=Shape>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss_1/num_present/broadcast_weights' type=Mul>,\n",
       " <tf.Operation 'log_loss_1/num_present/Const' type=Const>,\n",
       " <tf.Operation 'log_loss_1/num_present' type=Sum>,\n",
       " <tf.Operation 'log_loss_1/Const_1' type=Const>,\n",
       " <tf.Operation 'log_loss_1/Sum_1' type=Sum>,\n",
       " <tf.Operation 'log_loss_1/Greater/y' type=Const>,\n",
       " <tf.Operation 'log_loss_1/Greater' type=Greater>,\n",
       " <tf.Operation 'log_loss_1/Equal/y' type=Const>,\n",
       " <tf.Operation 'log_loss_1/Equal' type=Equal>,\n",
       " <tf.Operation 'log_loss_1/ones_like/Shape' type=Const>,\n",
       " <tf.Operation 'log_loss_1/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'log_loss_1/ones_like' type=Fill>,\n",
       " <tf.Operation 'log_loss_1/Select' type=Select>,\n",
       " <tf.Operation 'log_loss_1/div' type=RealDiv>,\n",
       " <tf.Operation 'log_loss_1/zeros_like' type=Const>,\n",
       " <tf.Operation 'log_loss_1/value' type=Select>,\n",
       " <tf.Operation 'gradients/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/zeros_like' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/Select_1' type=Select>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/value_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/RealDiv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/RealDiv_1' type=RealDiv>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/RealDiv_2' type=RealDiv>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/div_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_1_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_1_grad/Tile/multiples' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_1_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/zeros_like' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/Select_1' type=Select>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Select_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Sum_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/num_present_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/num_present_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/num_present_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/num_present_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights/ones_like_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/num_present/broadcast_weights/ones_like_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/sub_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Neg_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/Log_1_grad/Reciprocal' type=Reciprocal>,\n",
       " <tf.Operation 'gradients/log_loss/Log_1_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/Log_grad/Reciprocal' type=Reciprocal>,\n",
       " <tf.Operation 'gradients/log_loss/Log_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/add_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/log_loss/sub_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/AddN' type=AddN>,\n",
       " <tf.Operation 'gradients/transpose_grad/InvertPermutation' type=InvertPermutation>,\n",
       " <tf.Operation 'gradients/transpose_grad/transpose' type=Transpose>,\n",
       " <tf.Operation 'gradients/Sigmoid_grad/SigmoidGrad' type=SigmoidGrad>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/RealDiv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/RealDiv_1' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/RealDiv_2' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout_1/div_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/Relu_1_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/RealDiv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/RealDiv_1' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/RealDiv_2' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/div_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'beta1_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta1_power' type=VariableV2>,\n",
       " <tf.Operation 'beta1_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta1_power/read' type=Identity>,\n",
       " <tf.Operation 'beta2_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta2_power' type=VariableV2>,\n",
       " <tf.Operation 'beta2_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta2_power/read' type=Identity>,\n",
       " <tf.Operation 'W1/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W1/Adam' type=VariableV2>,\n",
       " <tf.Operation 'W1/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'W1/Adam/read' type=Identity>,\n",
       " <tf.Operation 'W1/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W1/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'W1/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'W1/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'b1/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b1/Adam' type=VariableV2>,\n",
       " <tf.Operation 'b1/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'b1/Adam/read' type=Identity>,\n",
       " <tf.Operation 'b1/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b1/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'b1/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'b1/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'W2/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W2/Adam' type=VariableV2>,\n",
       " <tf.Operation 'W2/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'W2/Adam/read' type=Identity>,\n",
       " <tf.Operation 'W2/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W2/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'W2/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'W2/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'b2/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b2/Adam' type=VariableV2>,\n",
       " <tf.Operation 'b2/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'b2/Adam/read' type=Identity>,\n",
       " <tf.Operation 'b2/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b2/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'b2/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'b2/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'W3/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W3/Adam' type=VariableV2>,\n",
       " <tf.Operation 'W3/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'W3/Adam/read' type=Identity>,\n",
       " <tf.Operation 'W3/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W3/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'W3/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'W3/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'b3/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b3/Adam' type=VariableV2>,\n",
       " <tf.Operation 'b3/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'b3/Adam/read' type=Identity>,\n",
       " <tf.Operation 'b3/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'b3/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'b3/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'b3/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'Adam/learning_rate' type=Const>,\n",
       " <tf.Operation 'Adam/beta1' type=Const>,\n",
       " <tf.Operation 'Adam/beta2' type=Const>,\n",
       " <tf.Operation 'Adam/epsilon' type=Const>,\n",
       " <tf.Operation 'Adam/update_W1/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_b1/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_W2/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_b2/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_W3/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_b3/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/mul' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'Adam/mul_1' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign_1' type=Assign>,\n",
       " <tf.Operation 'Adam' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63402367"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCosts(X_Dev, Y_Dev, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626561 0.635208\n"
     ]
    }
   ],
   "source": [
    "print(computeCosts(X_Train, Y_Train, params), computeCosts(X_Dev, Y_Dev, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47493479,  0.48097113,  0.49750122]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu.predict(X_Dev[:,:3], parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tf_utils' from 'C:\\\\Users\\\\darky\\\\Downloads\\\\!CS230\\\\ZSY\\\\tf_utils.py'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"Parameters_M1_100epochs.pkl\", 'wb+')\n",
    "pickle.dump(parameters_100k_model1, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"Parameters_100epochs_dropout.pkl\", 'rb')\n",
    "params = pickle.load(f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
